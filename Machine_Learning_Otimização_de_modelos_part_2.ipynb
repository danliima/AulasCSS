{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOpf9Vk0EO9CRuhqQud0iLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danliima/AulasCSS/blob/master/Machine_Learning_Otimiza%C3%A7%C3%A3o_de_modelos_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz==0.9\n",
        "!pip install pydot\n",
        "\n",
        "!apt-get install graphviz"
      ],
      "metadata": {
        "id": "WywyWvH6sNE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqPm_o-Tcrqt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
        "\n",
        "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
        "\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "k21FKL09eQ_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Situação de \"azar\" onde as classes estão ordenadas por padrão\n",
        "dados_azar =  dados.sort_values(\"vendido\", ascending=True)\n",
        "x_azar = dados_azar[[\"preco\", \"idade_do_modelo\", \"km_por_ano\"]]\n",
        "y_azar = dados_azar[\"vendido\"]\n",
        "dados_azar.head()"
      ],
      "metadata": {
        "id": "V1EH063ZedlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv=10, return_train_score=False)\n",
        "media = results[\"test_score\"].mean()\n",
        "desvio_padrao = results[\"test_score\"].std()\n",
        "print(\"Accuracy com cross validate: 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao) * 100, (media + 2 * desvio_padrao) * 100))\n"
      ],
      "metadata": {
        "id": "AGn-Rzc1e3FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gerando dados aleatórios de modelo de carro para simulação de agrupamento ao usar nosso estimador\n",
        "np.random.seed(SEED)\n",
        "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=10000)\n",
        "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
        "dados.head()"
      ],
      "metadata": {
        "id": "pHqh2uaSoquW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprime_resultados(results):\n",
        "    media = results[\"test_score\"].mean() * 100\n",
        "    desvio = results[\"test_score\"].std() * 100\n",
        "    print(\"Accuracy médio: %.2f\" % media)\n",
        "    print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
      ],
      "metadata": {
        "id": "a2CieIZEqLUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GroupKFold para analisar como o modelo se comporta com novos modelos\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits=10)\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "id": "mUBHbPgcqXfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GroupKFold em um pipeline com StandarScaler e SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "modelo = SVC()\n",
        "\n",
        "pipeline = Pipeline([('transformacao', scaler), ('estimador', modelo)])\n",
        "\n",
        "cv = GroupKFold(n_splits=10)\n",
        "results = cross_validate(pipeline, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "id": "FpnAaYFbrAvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GroupKFold para analisar como o modelo se comporta com novos modelos\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits=10)\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "id": "2N017qFUraaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "modelo.fit(x_azar, y_azar)\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, class_names=[\"não\", \"sim\"] ,feature_names=features)\n",
        "grafico = graphviz.Source(dot_data)\n",
        "grafico"
      ],
      "metadata": {
        "id": "0LQ5PCa-rmY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testando com a profundidade max de 3\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits=10)\n",
        "modelo = DecisionTreeClassifier(max_depth=3)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "id": "PZSD3Vp2rovv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.fit(x_azar, y_azar)\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, class_names=[\"não\", \"sim\"] ,feature_names=features)\n",
        "grafico = graphviz.Source(dot_data)\n",
        "grafico"
      ],
      "metadata": {
        "id": "xJfWhmC7tUV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testando com a profundidade max de 10\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits=10)\n",
        "modelo = DecisionTreeClassifier(max_depth=10)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ],
      "metadata": {
        "id": "kQH48-KGtWUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando os hiperparâmetros Parâmetros em uma dimensão"
      ],
      "metadata": {
        "id": "z8kUYFdXwsjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testando com a profundidade max de 10\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits=10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=True)\n",
        "  train_score = results[\"train_score\"].mean() * 100\n",
        "  test_score = results[\"test_score\"].mean() * 100\n",
        "  print(\"árvore max_depth = %d, treino = %.2f, teste = %.2f\" % (max_depth , train_score, test_score))\n",
        "  tabela = [max_depth, train_score, test_score]\n",
        "  return tabela\n",
        "\n",
        "  imprime_resultados(results)\n",
        "\n",
        "resultados = [roda_arvore_de_decisao(i) for i in range(1, 33)]\n",
        "resultados = pd.DataFrame(resultados, columns=[\"max_depth\", \"train\", \"test\"])\n",
        "resultados.head()\n"
      ],
      "metadata": {
        "id": "lWfctJSdti4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overfit: Ficou \"perfeito\" para o treino e ruim para o teste"
      ],
      "metadata": {
        "id": "dCJEAMTMNYl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.lineplot(x=\"max_depth\", y=\"train\", data=resultados)\n",
        "sns.lineplot(x=\"max_depth\", y=\"test\", data=resultados)\n",
        "plt.legend([\"Treino\", \"Teste\"])\n"
      ],
      "metadata": {
        "id": "M4mZXCgyyU4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ],
      "metadata": {
        "id": "VJ5LRw8JMiTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando os hiperparâmetros Parâmetros em 2 dimensão"
      ],
      "metadata": {
        "id": "jCdMG9pbVA1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testando com a profundidade max de 10\n",
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits=10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=True)\n",
        "  train_score = results[\"train_score\"].mean() * 100\n",
        "  test_score = results[\"test_score\"].mean() * 100\n",
        "  print(\"árvore max_depth = %d, min_samples_leaf = %d,treino = %.2f, teste = %.2f\" % (max_depth, min_samples_leaf, train_score, test_score))\n",
        "  tabela = [max_depth, min_samples_leaf,train_score, test_score]\n",
        "  return tabela\n",
        "\n",
        "  imprime_resultados(results)\n",
        "\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1, 33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:\n",
        "      tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
        "      resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns=[\"max_depth\",\"min_samples_leaf\", \"train\", \"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "uIWwELyANmOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ],
      "metadata": {
        "id": "Z2BEAeIEV7M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = resultados.corr()\n",
        "corr"
      ],
      "metadata": {
        "id": "1Xftjil3XD0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(corr, annot=True)"
      ],
      "metadata": {
        "id": "fHU6lqNwc15V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "uQ8fVPiMeLxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HioNcS_FeLiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(resultados)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aHlmzt14dTnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "id": "9GkSl0UNd2xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1, 33):\n",
        "    for min_samples_leaf in [128, 192, 256, 512]:\n",
        "      tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
        "      resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns=[\"max_depth\",\"min_samples_leaf\", \"train\", \"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "ZpL21CSpe0AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = resultados.corr()\n",
        "corr"
      ],
      "metadata": {
        "id": "LpFZZOsBfKrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"white\")\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "id": "8LT-ec4MfVmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ],
      "metadata": {
        "id": "FmseCsXIfWYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando 3 dimensões de hiper parâmetros"
      ],
      "metadata": {
        "id": "TFRzrir8PMnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testando com a profundidade max de 10\n",
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits=10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv=cv, groups=dados.modelo, return_train_score=True)\n",
        "  fit_time =  results['fit_time'].mean()\n",
        "  score_time = results['score_time'].mean()\n",
        "  train_score = results[\"train_score\"].mean() * 100\n",
        "  test_score = results[\"test_score\"].mean() * 100\n",
        "  tabela = [max_depth, min_samples_leaf, min_samples_split,train_score, test_score, fit_time, score_time]\n",
        "  return tabela\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1, 33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:\n",
        "      for min_samples_split in [32, 64, 128, 256]:\n",
        "        tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf,min_samples_leaf)\n",
        "        resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns=[\"max_depth\",\"min_samples_leaf\",\"min_samples_split\",\"train\", \"test\", \"fit_time\", \"score_time\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "ZIJZO01UfffQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = resultados.corr()\n",
        "corr"
      ],
      "metadata": {
        "id": "jnp8P1G7QVHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"white\")\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "id": "7Inb0zXeQvqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ],
      "metadata": {
        "id": "9n4dlBixQwl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando espaço de hiper parâmetros com GridSearchCV"
      ],
      "metadata": {
        "id": "YlIrkYj6Ym4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                     cv=GroupKFold(n_splits=10))\n",
        "busca.fit(x_azar, y_azar, groups=dados.modelo)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "yiSrthKJQ16I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(busca.best_params_)\n",
        "print(busca.best_score_ * 100)"
      ],
      "metadata": {
        "id": "DKB02zWEZ5p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor = busca.best_estimator_\n",
        "melhor"
      ],
      "metadata": {
        "id": "DjHW9_aJaS4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Evitar essa abordagem, porque ela está sendo otimista\n",
        "\n",
        "predicoes = melhor.predict(x_azar)\n",
        "accuracy =  accuracy_score(y_azar, predicoes)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100))"
      ],
      "metadata": {
        "id": "wOLU6pcxaYZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como ter uma estimativa sem esse vício nos dados que eu já vi?\n",
        "\n",
        "- Co caso de cross validation com busca de hiper parâmetros, fazemos uma nova validação cruzada. Chama-se nested cross validation."
      ],
      "metadata": {
        "id": "F557tdgMGmxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# scores = cross_val_score(melhor, x_azar, y_azar, cv=GroupKFold(n_splits=10))"
      ],
      "metadata": {
        "id": "kefM__Mxa443"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Infelismente como o pandas não suporta o nested validation com o groupKfold não conseguimos prever o resultado para novos grupos"
      ],
      "metadata": {
        "id": "-pnJcDI4IBpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                     cv=KFold(n_splits=5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "WrA2fR3wISDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(melhor, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
        "scores"
      ],
      "metadata": {
        "id": "vzNM5_HMI5Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprime_score(scores):\n",
        "  media = scores.mean() * 100\n",
        "  desvio = scores.std() * 100\n",
        "  print(\"Accuracy médio: %.2f\" % media)\n",
        "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))\n",
        "\n",
        "imprime_score(scores)\n"
      ],
      "metadata": {
        "id": "A-vafAGzJdBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor = busca.best_estimator_\n",
        "print(melhor)"
      ],
      "metadata": {
        "id": "DY6FZK-ZJtph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True, class_names=[\"não\", \"sim\"] ,feature_names=features)\n",
        "grafico = graphviz.Source(dot_data)\n",
        "grafico"
      ],
      "metadata": {
        "id": "Mh91gg_RJynS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explorando com valores aleatórios: RandonSearch"
      ],
      "metadata": {
        "id": "BxaS_GxUToYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                      n_iter=16,\n",
        "                     cv=KFold(n_splits=5, shuffle=True),\n",
        "                     random_state=SEED)\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "lgjmYPrtQ538"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(melhor, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
        "imprime_score(scores)"
      ],
      "metadata": {
        "id": "wGD9MgtQVo5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor = busca.best_estimator_\n",
        "print(melhor)"
      ],
      "metadata": {
        "id": "y_iHMlUWVzPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True, class_names=[\"não\", \"sim\"] ,feature_names=features)\n",
        "grafico = graphviz.Source(dot_data)\n",
        "grafico"
      ],
      "metadata": {
        "id": "V9Ya_xIKWEeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizando o espaço de hiper parâmetros"
      ],
      "metadata": {
        "id": "WBQG6iOAYFMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\": [3, 5, 10, 15, 20, 30, None],\n",
        "    \"min_samples_leaf\": randint(32, 128),\n",
        "    \"min_samples_split\": randint(32, 128),\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                      n_iter=16,\n",
        "                     cv=KFold(n_splits=5, shuffle=True),\n",
        "                     random_state=SEED)\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "IORh-x9TWZDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(melhor, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)"
      ],
      "metadata": {
        "id": "LnIVI_ZqZGPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_ordenados_pela_media =  resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media.iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score * 2, linha.params))"
      ],
      "metadata": {
        "id": "iWdNJ3NyZO51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploração mais a fundo de forma aleatória"
      ],
      "metadata": {
        "id": "G4mQMMQhmFYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 564\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\": [3, 5, 10, 15, 20, 30, None],\n",
        "    \"min_samples_leaf\": randint(32, 128),\n",
        "    \"min_samples_split\": randint(32, 128),\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "busca = RandomizedSearchCV(DecisionTreeClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                      n_iter=64,\n",
        "                     cv=KFold(n_splits=5, shuffle=True),\n",
        "                     random_state=SEED)\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "5VBnnvBEk2vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_ordenados_pela_media =  resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media.iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score * 2, linha.params))"
      ],
      "metadata": {
        "id": "8DxsLxGOmKlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparando GridSearchCV com RandomizedSearsh (1comparação)\n"
      ],
      "metadata": {
        "id": "sfumsjJqsso4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\": [10, 100],\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"bootstrap\": [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "tic= time.time()\n",
        "busca = GridSearchCV(RandomForestClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                     cv=KFold(n_splits=5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo gasto: %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "DOWvlzV2mQ3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_ordenados_pela_media =  resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score * 2, linha.params))"
      ],
      "metadata": {
        "id": "623fbp1Jur_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\": [10, 100],\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"bootstrap\": [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "tic= time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                      n_iter = 20,\n",
        "                     cv=KFold(n_splits=5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo gasto: %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "aikxg-J4vu6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_ordenados_pela_media =  resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media[:5].iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score * 2, linha.params))"
      ],
      "metadata": {
        "id": "UQCoiQcp0yz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic= time.time()\n",
        "scores = cross_val_score(busca.best_estimator_, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo gasto: %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "imprime_score(scores)\n",
        "melhor = busca.best_estimator_\n",
        "print(melhor)"
      ],
      "metadata": {
        "id": "_JiWthG71Ghr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\": randint(10, 101),\n",
        "    \"max_depth\": randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\": [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "tic= time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                      n_iter = 80,\n",
        "                     cv=KFold(n_splits=5, shuffle=True))\n",
        "busca.fit(x_azar, y_azar)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo gasto: %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "3G1OzBe51irh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_ordenados_pela_media =  resultados.sort_values(\"mean_test_score\", ascending=False)\n",
        "for indice, linha in resultados_ordenados_pela_media[-5:].iterrows():\n",
        "  print(\"%.3f +-(%.3f) %s\" % (linha.mean_test_score, linha.std_test_score * 2, linha.params))"
      ],
      "metadata": {
        "id": "uoMrD_662Yrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se eu não posso ou não consigo usar o cross validation"
      ],
      "metadata": {
        "id": "rOpx7zJEHZQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.6 treino  => treino\n",
        "# 0.2 teste    => dev test\n",
        "# 0.2 validação  => validação\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "x_treino_teste, x_validacao, y_treino_teste, y_validacao = train_test_split(x_azar, y_azar, test_size=0.2, shuffle=True, stratify=y_azar)\n",
        "print(x_treino_teste.shape)\n",
        "print(x_validacao.shape)\n",
        "print(y_treino_teste.shape)\n",
        "print(y_validacao.shape)"
      ],
      "metadata": {
        "id": "kZBDOxcZJCfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"n_estimators\": randint(10, 101),\n",
        "    \"max_depth\": randint(3, 6),\n",
        "    \"min_samples_split\": randint(32, 129),\n",
        "    \"min_samples_leaf\": randint(32, 129),\n",
        "    \"bootstrap\": [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "splits = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\n",
        "\n",
        "tic= time.time()\n",
        "busca = RandomizedSearchCV(RandomForestClassifier(),\n",
        "                     espaco_de_parametros,\n",
        "                      n_iter = 5,\n",
        "                     cv=splits)\n",
        "busca.fit(x_treino_teste, y_treino_teste)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo gasto: %.2f segundos\" % tempo_que_passou)\n",
        "\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "_ZgM1lFQ2-Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic= time.time()\n",
        "scores = cross_val_score(busca, x_validacao, y_validacao, cv=splits)\n",
        "tac = time.time()\n",
        "tempo_que_passou = tac - tic\n",
        "print(\"Tempo gasto: %.2f segundos\" % tempo_que_passou)\n",
        "scores"
      ],
      "metadata": {
        "id": "axQwxmGlIn8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJ5kUAh3LnZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}